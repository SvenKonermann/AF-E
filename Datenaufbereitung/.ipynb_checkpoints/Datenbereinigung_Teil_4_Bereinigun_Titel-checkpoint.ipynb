{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156f39c2",
   "metadata": {},
   "source": [
    "# __Datenbereinigung Teil 4: Bereinigung der Anforderungsdaten__\n",
    "\n",
    "In diesem Schritt werden die Daten bereinigt, welche für das Wörterbuch mit den häufigst genannten Jobtiteln benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cca9d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import der benötigten Libraries\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from bs4 import BeautifulSoup\n",
    "from HanTa import HanoverTagger as ht\n",
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import os\n",
    "\n",
    "# Working-Directory\n",
    "os.chdir('C:/Users/Sven Konermann/Documents/Master/2_Semester/aF_E_Faelle/Unterlagen/00_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df60a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25100, 15)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25100 entries, 0 to 25099\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0.1           25100 non-null  int64  \n",
      " 1   Unnamed: 0             25100 non-null  int64  \n",
      " 2   ad_id                  25100 non-null  object \n",
      " 3   active_start_on        25100 non-null  object \n",
      " 4   active_end_on          25100 non-null  object \n",
      " 5   title                  25100 non-null  object \n",
      " 6   text                   25100 non-null  object \n",
      " 7   branchen_name          24926 non-null  object \n",
      " 8   customer_branche_name  25099 non-null  object \n",
      " 9   lvl1_region_name       25065 non-null  object \n",
      " 10  region_name            25065 non-null  object \n",
      " 11  lvl1_jobcategory_name  25093 non-null  object \n",
      " 12  jobcategory_name       25093 non-null  object \n",
      " 13  duration               25100 non-null  float64\n",
      " 14  year                   25100 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(11)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Einlesen der Daten über ein csv File\n",
    "data = pd.read_csv(\"Inserate_Anforderungsanalyse_AF_E.csv\", sep=\";\")\n",
    "print(data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433ec05d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m title\u001b[38;5;241m=\u001b[39m i\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#soup = BeautifulSoup(i, 'lxml')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#tags = soup.find_all('li')\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#print(tags)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtags\u001b[49m:\n\u001b[0;32m     11\u001b[0m     title \u001b[38;5;241m=\u001b[39m title \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m t\u001b[38;5;241m.\u001b[39mtitle \n\u001b[0;32m     12\u001b[0m column\u001b[38;5;241m.\u001b[39mappend(title)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tags' is not defined"
     ]
    }
   ],
   "source": [
    "# Listenelemente in einer neuen Spalte abspeichern\n",
    "start = time()\n",
    "\n",
    "column = []\n",
    "for i in data['title']:\n",
    "    title= i\n",
    "    #soup = BeautifulSoup(i, 'lxml')\n",
    "    #tags = soup.find_all('li')\n",
    "    #print(tags)\n",
    "    for t in tags:\n",
    "        title = title + ' ' + t.title \n",
    "    column.append(title)\n",
    "\n",
    "data['Title_Anforderungen'] = column\n",
    "\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5365fabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 216.8528733253479 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Lemmatisierung der Titel\n",
    "start = time()\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "for mail in data['Title_Anforderungen']:\n",
    "    lemma = [lemma for (word,lemma,pos) in tagger.tag_sent(mail.split())]\n",
    "    index = data[data['Title_Anforderungen']==mail].index\n",
    "    data.loc[index, 'Title_Anforderungen'] = (' '.join(lemma))\n",
    "    \n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e566da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in Kleinbuchstaben umwandeln\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10ddf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satzzeichen löschen\n",
    "def remove_punctuation(txt):\n",
    "    txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunct\n",
    "\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56783be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               projektleiter sap inkasso  exkasso fscd wm\n",
       "1                                       it projektleiterin\n",
       "2                         it und organsationsprojektleiter\n",
       "3        it gesamtprojektleiter  senior it project mana...\n",
       "4        it projektmanager ¶®application¶¯ deutsch fran...\n",
       "                               ...                        \n",
       "25095      sachbearbeiterin buchhaltung per sofort tryhire\n",
       "25096    sachbearbeiterin administration und buchhaltun...\n",
       "25097                              jung leiter buchhaltung\n",
       "25098    sachbearbeiterin buchhaltung  projektunterstüt...\n",
       "25099    sachbearbeiter buchhaltung als buchhaltungsmit...\n",
       "Name: Title_Anforderungen, Length: 25100, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabs \\t aus den Texten entfernen\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"\\t\", \"\", regex=True)\n",
    "data['Title_Anforderungen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb3a192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ähnliche Anforderungen manuell mit einem Hauptbegriff ersetzen\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"teamplayer\", \"teamfähig\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"verhandlungssicher\", \"verhandlungsgeschick\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"kundenorientierte\", \"kundenorientierung\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"projekt management\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"projektmanagement\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"zusammenarbeit\", \"teamfähig\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"kommunikation\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"kommunikationsfähigkeiten\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"dwh\", \"data warehouse\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"dienstleistungsorientierung\", \"dienstleistungsorientiert\", regex=True)\n",
    "data['Title_Anforderungen'] = data['Title_Anforderungen'].str.replace(\"eigenverantwortung\", \"eigenverantwortlich\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413eba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 3.345613479614258 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Word-Tokenization \n",
    "#nltk.download('punkt')\n",
    "\n",
    "start = time()\n",
    "data['title_tok'] = data.apply(lambda row: nltk.word_tokenize(row['Title_Anforderungen']), axis=1)\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc8dc387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sven\n",
      "[nltk_data]     Konermann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Stopwörter löschen\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('german'))\n",
    "data['title_tok'] = data['title_tok'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b1c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing rückgängig machen, da die Tokenizierung nicht in eine csv-Datei überführt werden kann\n",
    "column = []\n",
    "for i in data['title_tok']:\n",
    "    test = TreebankWordDetokenizer().detokenize(i)\n",
    "    column.append(test)\n",
    "\n",
    "data['Title_Anforderungen'] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "590bd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen der tokenisierten Spalte\n",
    "data = data.drop(['title_tok'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7c3a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erneutes Löschen der Duplikate, da sich die Texte verändert haben\n",
    "data = data.drop_duplicates(subset='Title_Anforderungen', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5459378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Inserate_clean_Titelanalyse_AF_E.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
