{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Datenbereinigung Teil 3: Bereinigung der Gesamtdaten__\n",
    "\n",
    "In diesem Schritt werden die Gesamtdaten bereinigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import os\n",
    "\n",
    "# Working-Directory\n",
    "os.chdir('C:/Users/Sven Konermann/Documents/Master/2_Semester/aF_E_Faelle/Unterlagen/00_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0           ad_id active_start_on active_end_on  \\\n",
      "0             6           6  jobsse-5759852      04.10.2014    05.05.2014   \n",
      "1             7           7  jobsse-5879310      19.06.2014    14.07.2014   \n",
      "2            12          12  jobsse-5700844      14.03.2014    26.03.2014   \n",
      "3            13          13  jobsse-6271598      19.02.2015    27.02.2015   \n",
      "4            15          15  jobsse-5634978      02.07.2014    02.11.2014   \n",
      "\n",
      "                                               title  \\\n",
      "0                          IT-Projektleiter/in 100 %   \n",
      "1  Projektleiter SAP Inkasso / Exkasso (FS-CD) (w/m)   \n",
      "2                         ICT-Projektleiter (60-70%)   \n",
      "3                        Projektleiter im SAP-Umfeld   \n",
      "4                         IT- Projektleiter (Senior)   \n",
      "\n",
      "                                                text  year  \n",
      "0  IT-Projektleiter/in, Ref.-Nr. 39892D        Be...  2014  \n",
      "1  <div id=\"jobTplContainer\" style=\"overflow: hid...  2014  \n",
      "2  <p><strong>Referenz Nr.:</strong>   4777SM   <...  2014  \n",
      "3  <p><strong>Referenz Nr.: </strong>5045TG    <s...  2015  \n",
      "4  <p>Hauptaufgaben: <br />- Management von gross...  2014  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41922 entries, 0 to 41921\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Unnamed: 0.1     41922 non-null  int64 \n",
      " 1   Unnamed: 0       41922 non-null  int64 \n",
      " 2   ad_id            41922 non-null  object\n",
      " 3   active_start_on  41922 non-null  object\n",
      " 4   active_end_on    41922 non-null  object\n",
      " 5   title            41922 non-null  object\n",
      " 6   text             41922 non-null  object\n",
      " 7   year             41922 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Einlesen der Daten über ein csv File\n",
    "data = pd.read_csv(\"Inserate_Gesamtdatenanalyse.csv\", sep=\";\")\n",
    "data.shape\n",
    "#data = data.dropna()\n",
    "\n",
    "print(data.head(5))\n",
    "data.info()\n",
    "#data.to_csv(\"Inserate_clean_Test.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    IT-Projektleiter/in, Ref.-Nr. 39892D        Be...\n",
      "1        Daniel Kapetanovic Leiter Rechnungswesen S...\n",
      "2    Referenz Nr.:   4777SM    Branche:   BehÇôrden...\n",
      "3    Referenz Nr.: 5045TG    Einsatzort: ZÇ¬rich   ...\n",
      "4    Hauptaufgaben: - Management von grossen und ko...\n",
      "Name: Text_Anforderungen, dtype: object\n",
      "--------------------------\n",
      "(41922, 9)\n",
      "--------------------------\n",
      "Benötigte Zeit: 37.52906155586243 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# HTML-Elemente in einer neue Spalte 'Text_Anforderungen' abspeichern\n",
    "\n",
    "start = time()\n",
    "\n",
    "column = []\n",
    "for i in data['text']:\n",
    "    text=''\n",
    "    soup = BeautifulSoup(i, 'lxml')\n",
    "    text = soup.text \n",
    "    column.append(text)\n",
    "\n",
    "data['Text_Anforderungen'] = column\n",
    "\n",
    "print(data.Text_Anforderungen[0:5])\n",
    "print('--------------------------')\n",
    "print(data.shape)\n",
    "print('--------------------------')\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 9854.210126161575 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Lemmatisierung der Gesamtdaten (kann je nach Datenmenge länger dauern).\n",
    "from HanTa import HanoverTagger as ht\n",
    "start = time()\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "for mail in data['Text_Anforderungen']:\n",
    "    lemma = [lemma for (word,lemma,pos) in tagger.tag_sent(mail.split())]\n",
    "    index = data[data['Text_Anforderungen']==mail].index\n",
    "    data.loc[index, 'Text_Anforderungen'] = (' '.join(lemma))\n",
    "    \n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in Kleinbuchstaben umwandeln\n",
    "data['Text_Anforderungen'] = (data['Text_Anforderungen'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satzzeichen löschen\n",
    "def remove_punctuation(txt):\n",
    "    txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunct\n",
    "\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\t-Tag entfernen aus den Texten\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"\\t\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuell ähnliche Anforderungen zu einem Hauptbegriff ersetzen\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"teamplayer\", \"teamfähig\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"verhandlungssicher\", \"verhandlungsgeschick\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kundenorientierte\", \"kundenorientierung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"projekt management\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"projektmanagement\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"zusammenarbeit\", \"teamfähig\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kommunikation\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kommunikationsfähigkeiten\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"dwh\", \"data warehouse\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"dienstleistungsorientierung\", \"dienstleistungsorientiert\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"eigenverantwortung\", \"eigenverantwortlich\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 33.74079489707947 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Word-Tokenization \n",
    "start = time()\n",
    "data['text_tok'] = data.apply(lambda row: nltk.word_tokenize(row['Text_Anforderungen']), axis=1)\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwörter löschen\n",
    "stop_words = set(stopwords.words('german'))\n",
    "data['text_tok'] = data['text_tok'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing rückgängig machen, da die Tokenizierung nicht in eine csv-Datei überführt werden kann\n",
    "column = []\n",
    "for i in data['text_tok']:\n",
    "    test = TreebankWordDetokenizer().detokenize(i)\n",
    "    column.append(test)\n",
    "\n",
    "data['Text_Anforderungen'] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen der tokenisierten Spalte\n",
    "data = data.drop(['text_tok'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erneutes Löschen der Duplikate, da sich die Texte verändert haben\n",
    "data = data.drop_duplicates(subset='Text_Anforderungen', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Inserate_clean_Gesamtdatenanalyse.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nächster Schritt: Mithilfe der erstellten Wörterbücher, die Gesamtdatenanalyse durchführen (Gesamtdatenanalyse.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
