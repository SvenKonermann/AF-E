{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Datenbereinigung Teil 3: Bereinigung der Gesamtdaten__\n",
    "\n",
    "In diesem Schritt werden die Gesamtdaten bereinigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import os\n",
    "\n",
    "# Working-Directory\n",
    "os.chdir('C:/Users/Sven Konermann/Documents/Master/2_Semester/aF_E_Faelle/Unterlagen/JobCloud_Daten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            ad_id active_start_on active_end_on  \\\n",
      "0           5  jobsse-10107990      2021-01-07    2021-01-15   \n",
      "1           7   jobsse-8132125      2018-04-17    2018-04-18   \n",
      "2          11   jobsse-6058207      2014-10-06    2014-11-07   \n",
      "3          13   jobsse-5875311      2014-06-17    2014-06-20   \n",
      "4          14   jobsse-6012460      2014-09-09    2014-09-16   \n",
      "\n",
      "                                      title  \\\n",
      "0               Lead Solution Architect IoT   \n",
      "1   Konstrukteur/In (auch Teilzeit möglich)   \n",
      "2  Kaufmännische(n) Angestellte(n) 80%-100%   \n",
      "3          Hauswirtschaftsmitarbeiter (m/w)   \n",
      "4                     Kindergärtner/in 85 %   \n",
      "\n",
      "                                                text  \\\n",
      "0  Lead Solution Architect IoT Als Lead Solution ...   \n",
      "1  <p><strong>Ihre Hauptaufgaben</strong></p><ul>...   \n",
      "2  <p><strong>Wir z&auml;hlen auf Sie:</strong></...   \n",
      "3  Das Widder Hotel Moderne Architektur in 9 hist...   \n",
      "4  Kindergärtner/in, Ref.-Nr. 41427D        Bezei...   \n",
      "\n",
      "                   branchen_name          customer_branche_name  \\\n",
      "0   Informatik/Telekommunikation               Beratung diverse   \n",
      "1     Gewerbe/Handwerk allgemein               Personalberatung   \n",
      "2        Banken/ Finanzinstitute        Banken/ Finanzinstitute   \n",
      "3         Gastgewerbe/Hotellerie         Gastgewerbe/Hotellerie   \n",
      "4  öffentl. Verwaltung/ Verbände  öffentl. Verwaltung/ Verbände   \n",
      "\n",
      "             lvl1_region_name                 region_name  \\\n",
      "0                 Region Bern                 Region Bern   \n",
      "1  Region Mittelland (AG, SO)  Region Mittelland (AG, SO)   \n",
      "2       Region Zentralschweiz       Region Zentralschweiz   \n",
      "3                         NaN                         NaN   \n",
      "4                         NaN                         NaN   \n",
      "\n",
      "                lvl1_jobcategory_name                  jobcategory_name  \\\n",
      "0        Informatik/Telekommunikation  Software Architektur/Engineering   \n",
      "1    Maschinen-/Anlagenbau/Produktion                      Konstruktion   \n",
      "2    Administration/HR/Consulting/CEO               Sekretariat/Empfang   \n",
      "3  Gastronomie/Lebensmittel/Tourismus    Zimmer/Lingerie/Hauswirtschaft   \n",
      "4         Verwaltung/Bildung/Soziales                   Lehrer/Dozenten   \n",
      "\n",
      "   duration  year  \n",
      "0         8  2021  \n",
      "1         1  2018  \n",
      "2        32  2014  \n",
      "3         3  2014  \n",
      "4         7  2014  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 134074 entries, 0 to 134073\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   Unnamed: 0             134074 non-null  int64 \n",
      " 1   ad_id                  134074 non-null  object\n",
      " 2   active_start_on        134074 non-null  object\n",
      " 3   active_end_on          134074 non-null  object\n",
      " 4   title                  134074 non-null  object\n",
      " 5   text                   134074 non-null  object\n",
      " 6   branchen_name          133368 non-null  object\n",
      " 7   customer_branche_name  134068 non-null  object\n",
      " 8   lvl1_region_name       128536 non-null  object\n",
      " 9   region_name            128536 non-null  object\n",
      " 10  lvl1_jobcategory_name  133407 non-null  object\n",
      " 11  jobcategory_name       133407 non-null  object\n",
      " 12  duration               134074 non-null  int64 \n",
      " 13  year                   134074 non-null  int64 \n",
      "dtypes: int64(3), object(11)\n",
      "memory usage: 14.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Einlesen der Daten über ein csv File\n",
    "data = pd.read_csv(\"Inserate_Gesamtdatenanalyse_AF_E.csv\", sep=\";\")\n",
    "data.shape\n",
    "#data = data.dropna()\n",
    "\n",
    "print(data.head(5))\n",
    "data.info()\n",
    "#data.to_csv(\"Inserate_clean_Test.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sven Konermann\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \"/\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sven Konermann\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \"...\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Lead Solution Architect IoT Als Lead Solution ...\n",
      "1    Ihre HauptaufgabenTeile in verschiedenen Softw...\n",
      "2    Wir zählen auf Sie:Sie führen einen Teilbereic...\n",
      "3    Das Widder Hotel Moderne Architektur in 9 hist...\n",
      "4    Kindergärtner/in, Ref.-Nr. 41427D        Bezei...\n",
      "Name: Text_Anforderungen, dtype: object\n",
      "--------------------------\n",
      "(134074, 15)\n",
      "--------------------------\n",
      "Benötigte Zeit: 130.97111988067627 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# HTML-Elemente in einer neue Spalte 'Text_Anforderungen' abspeichern\n",
    "\n",
    "start = time()\n",
    "\n",
    "column = []\n",
    "for i in data['text']:\n",
    "    text=''\n",
    "    soup = BeautifulSoup(i, 'lxml')\n",
    "    text = soup.text \n",
    "    column.append(text)\n",
    "\n",
    "data['Text_Anforderungen'] = column\n",
    "\n",
    "print(data.Text_Anforderungen[0:5])\n",
    "print('--------------------------')\n",
    "print(data.shape)\n",
    "print('--------------------------')\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 27883.0457572937 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Lemmatisierung der Gesamtdaten (kann je nach Datenmenge länger dauern).\n",
    "from HanTa import HanoverTagger as ht\n",
    "start = time()\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "for mail in data['Text_Anforderungen']:\n",
    "    lemma = [lemma for (word,lemma,pos) in tagger.tag_sent(mail.split())]\n",
    "    index = data[data['Text_Anforderungen']==mail].index\n",
    "    data.loc[index, 'Text_Anforderungen'] = (' '.join(lemma))\n",
    "    \n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text in Kleinbuchstaben umwandeln\n",
    "data['Text_Anforderungen'] = (data['Text_Anforderungen'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satzzeichen löschen\n",
    "def remove_punctuation(txt):\n",
    "    txt_nopunct = \"\".join([c for c in txt if c not in string.punctuation])\n",
    "    return txt_nopunct\n",
    "\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\t-Tag entfernen aus den Texten\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"\\t\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manuell ähnliche Anforderungen zu einem Hauptbegriff ersetzen\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"teamplayer\", \"teamfähig\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"verhandlungssicher\", \"verhandlungsgeschick\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kundenorientierte\", \"kundenorientierung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"projekt management\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"projektmanagement\", \"projektleitungserfahrung\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"zusammenarbeit\", \"teamfähig\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kommunikation\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"kommunikationsfähigkeiten\", \"kommunikationsfähigkeit\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"dwh\", \"data warehouse\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"dienstleistungsorientierung\", \"dienstleistungsorientiert\", regex=True)\n",
    "data['Text_Anforderungen'] = data['Text_Anforderungen'].str.replace(\"eigenverantwortung\", \"eigenverantwortlich\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Zeit: 82.30526733398438 Sekunden\n"
     ]
    }
   ],
   "source": [
    "# Word-Tokenization \n",
    "start = time()\n",
    "data['text_tok'] = data.apply(lambda row: nltk.word_tokenize(row['Text_Anforderungen']), axis=1)\n",
    "print(f'Benötigte Zeit: {time() - start} Sekunden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwörter löschen\n",
    "stop_words = set(stopwords.words('german'))\n",
    "data['text_tok'] = data['text_tok'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing rückgängig machen, da die Tokenizierung nicht in eine csv-Datei überführt werden kann\n",
    "column = []\n",
    "for i in data['text_tok']:\n",
    "    test = TreebankWordDetokenizer().detokenize(i)\n",
    "    column.append(test)\n",
    "\n",
    "data['Text_Anforderungen'] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Löschen der tokenisierten Spalte\n",
    "data = data.drop(['text_tok'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erneutes Löschen der Duplikate, da sich die Texte verändert haben\n",
    "data = data.drop_duplicates(subset='Text_Anforderungen', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Inserate_clean_Gesamtdatenanalyse.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nächster Schritt: Mithilfe der erstellten Wörterbücher, die Gesamtdatenanalyse durchführen (Gesamtdatenanalyse.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
