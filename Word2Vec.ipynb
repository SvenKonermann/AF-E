{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Word2Vec-Analyse auf die Gesamtdaten__\n",
    "\n",
    "Hier wird die Word2Vec Analyse durchgeführt\n",
    "\n",
    "Funktioniert nur mit einem grossen Datensatz. Mit den Beispiel-Stellenanzeigen ist eine Word2Vec-Auswertung nicht möglich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import benötigter Libraries\n",
    "import pandas as pd\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from time import time \n",
    "from collections import defaultdict \n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "import os\n",
    "\n",
    "# Working-Directory\n",
    "os.chdir('U:/Projekte/Stellenmarkt_Analyse/Daten')\n",
    "\n",
    "# Nur fürs debuggen\n",
    "# import logging \n",
    "# logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der gesäuberten Gesamtdaten\n",
    "data = pd.read_csv(\"Bereinigte_Gesamtdaten.csv\", sep=\",\")\n",
    "data = data[~data['Text_Anforderungen'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jahr auswählen, für das die Word2Vec-Analyse erstellt werden soll\n",
    "df = data.loc[data.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auszuwertende Anforderungen in ein neues DataFrame \n",
    "df_clean = pd.DataFrame()\n",
    "df_clean['clean'] = df['Text_Anforderungen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wörter splitten in den einzelnen Spalten\n",
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim Phrasen-Modell initiieren. Erstellt Phrasen welche mehr als 15x vorkommen\n",
    "phrases = Phrases(sent, min_count=15, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wird nicht benötigt\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setzen\n",
    "w2v_model = Word2Vec(min_count=15, #Mind. 15x muss das Wort vorkommen. Mit Beispieldaten nicht möglich\n",
    "                     window=5, #5 wörter vor und nach werden berücksichtigt\n",
    "                     size=300,\n",
    "                     workers=multiprocessing.cpu_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vokabular aufbauen und Modell initialisierung\n",
    "t = time()\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell trainieren\n",
    "t = time()\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=100, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir das Modell nicht weitertrainieren wollen, wird init_sims aufgerufen. Damit das Modell effizienter wird.\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelle 7 in Bachelorarbeit\n",
    "# Top 20 kontextähnlichsten Wörter zu cloud finden\n",
    "w2v_model.wv.most_similar(positive=[\"cloud\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabelle 5 in Bachelorarbeit\n",
    "# Top 20 kontextähnlichsten Wörter zu sap finden\n",
    "w2v_model.wv.most_similar(positive=[\"sap\"], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"englisch\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
